{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c185caf-e48d-42d8-92ea-dac53f7b4b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tibuch/pytorch-rdc-net/.pixi/envs/jupyter/lib/python3.12/site-packages/ignite/handlers/checkpoint.py:16: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import ZeroRedundancyOptimizer\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import yaml\n",
    "from faim_ipa.utils import get_git_root\n",
    "\n",
    "sys.path.append(str(get_git_root()))\n",
    "\n",
    "from source.rdcnet.model import RDCNet2d\n",
    "from source.data.MoNuSeg import MoNuSeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2f2827e-a30d-4d71-971d-87f35559cbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = MoNuSeg(get_git_root() / \"raw_data\" / \"MoNuSeg_dataset.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8adec0bf-1926-4d49-ae5b-4086cda31faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RDCNet2d.load_from_checkpoint(\"/home/tibuch/pytorch-rdc-net/processed_data/0a550d5_MoNuSeg-baseline/lightning_logs/version_0/checkpoints/rdcnet-epoch=80-f1=0.78.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e15629a5-5ee7-4e74-853c-c815e9dd445b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from napari import Viewer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0b13d95-26f0-4f8d-af95-3f1dafdc7b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Could not find the Qt platform plugin \"wayland\" in \"\"\n"
     ]
    }
   ],
   "source": [
    "viewer = Viewer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f508c64d-1f8f-4b88-b64b-b9c17b29991a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in dm.test_dataloader():\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61459d62-a6d5-497d-b0c2-9ce3d6a66609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'Image' at 0x7aad770ef890>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer.add_image(x[0].detach().moveaxis(0, -1), rgb=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9b48a89-a133-479d-92df-4b21897d9475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Labels layer 'GT' at 0x7aaedcee8da0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer.add_labels(y[0,0].detach().cpu(), name='GT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3a8664b-a17c-41e6-af92-cad4047a40d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = model.predict_instances(x.to(model.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ceeeff3d-0459-43e2-9de6-c3b7305cf3d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Labels layer 'instances' at 0x7aad8b455430>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer.add_labels(instances[0,0], name='instances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2408b9e8-eba7-4755-8aca-17b704100f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    pred = model(x.to(model.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e82c4631-3641-4da3-ae75-7de20809a52a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58032231-65b3-4139-8c5b-3cedf25518e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torchist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cbaa5041-3400-4f31-8e47-74cbcbaa206a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings, weights,  semantic_classes = pred\n",
    "\n",
    "embeddings = embeddings.detach()\n",
    "weights = weights.detach()\n",
    "semantic = semantic_classes.detach()\n",
    "\n",
    "padding = model.hparams.margin * 2\n",
    "embeddings = F.pad(embeddings, (padding, padding, padding, padding))\n",
    "semantic = F.pad(semantic, (padding, padding, padding, padding))\n",
    "\n",
    "shape = embeddings.shape[-2:]\n",
    "\n",
    "fg_mask = torch.argmax(semantic[0], dim=0).type(torch.bool)\n",
    "\n",
    "grid = model._get_coordinate_grid(embeddings)\n",
    "embeddings = (embeddings + grid)[0]\n",
    "fg_embeddings = torch.round(embeddings[:, fg_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb6434a9-f760-4c8f-8366-a2978f27ee01",
   "metadata": {},
   "outputs": [],
   "source": [
    "votes = torchist.histogramdd(\n",
    "                fg_embeddings.moveaxis(0, -1),\n",
    "                bins=(shape[0], shape[1]),\n",
    "                low=(0, 0),\n",
    "                upp=shape,\n",
    "            )\n",
    "# votes[votes < model.hparams.margin] = 0\n",
    "# votes[fg_mask == 0] = 0\n",
    "\n",
    "# threshold = torch.std(votes.type(torch.float32)).detach()\n",
    "# print(threshold)\n",
    "# votes[votes <= threshold] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36f9465e-f049-42a2-9d69-f6f5b8debe2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#viewer.add_image(votes[padding:-padding, padding:-padding].detach().cpu(), name='votes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d52e6292-6faf-414d-a2ea-c294eebe7e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_filtered = torch.clip(F.max_pool2d(\n",
    "    votes.unsqueeze(0).type(torch.float32),\n",
    "    kernel_size=model.hparams.margin * 2 +1,\n",
    "    stride=1,\n",
    "    padding=model.hparams.margin,\n",
    ")[0]-1, 0, votes.max())\n",
    "# votes[votes > 0] += 1\n",
    "\n",
    "# select embeddings which are less than margin away from any center\n",
    "centers = (torch.clip(votes - max_filtered, 0, 1).type(torch.bool) * votes ) >= model.hparams.margin\n",
    "center_coords = grid[0, :, centers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a07a703-c654-4576-b0d5-e26db5bff5b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 674])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "center_coords.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ec86058-ae8e-413f-b48d-9acfe7d9c263",
   "metadata": {},
   "outputs": [],
   "source": [
    "dists = torch.norm(grid[0].unsqueeze(1) - center_coords.unsqueeze(-1).unsqueeze(-1), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5ff9106-ffb8-478b-a4ce-9a888ca0bafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "vote_dists = torch.concat([torch.ones_like(dists[:1]) * (dists.shape[0] + 1), dists], dim=0) * (votes.unsqueeze(0) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d83a6ec6-521c-46b9-ae9e-60c65f7487e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_center = torch.argmin(vote_dists, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "da62ded1-c71d-44a6-8672-30e9a95b8a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ignite.utils import to_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9f0ad6bd-0c71-4ba8-9a3f-5723b0bd4f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_onehot = to_onehot(closest_center.unsqueeze(0).detach(), num_classes=closest_center.max()+1)[0, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a857dc06-eadd-405b-a2e3-cedb2434428d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scattered_votes = votes.type(torch.int32).unsqueeze(0) * cc_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e146373a-b028-41f3-a160-15f8a3eb387c",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimated_centers = []\n",
    "covs = []\n",
    "m = torch.stack([g.ravel() for g in grid[0]])\n",
    "for sv, oh in zip(scattered_votes, cc_onehot):\n",
    "    pred_centers = grid[0] * oh.unsqueeze(0)\n",
    "    estimated_centers.append(\n",
    "        torch.sum(grid[0] * sv.unsqueeze(0), dim=(1, 2)) / torch.sum(sv)\n",
    "    )\n",
    "    cov = torch.cov(m, fweights=sv.ravel())\n",
    "    \n",
    "    if not torch.any(torch.isnan(cov)) and torch.det(cov) > 0:\n",
    "        covs.append(\n",
    "            cov\n",
    "        )\n",
    "    else:\n",
    "        covs.append(\n",
    "            torch.eye(2).to(sv.device)\n",
    "        )\n",
    "\n",
    "estimated_centers = torch.stack(estimated_centers)\n",
    "covs = torch.stack(covs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cc53f144-3a10-4cb6-ba18-cfbd29cd2bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#viewer.add_points(estimated_centers.detach().cpu().numpy()-padding, face_color=\"#00000000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8da05915-2e79-48ff-87c5-cb554c523e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "95c0774e-b499-41b0-9ada-b1d67386ce29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#viewer.add_image(scattered_votes[i].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "236cbc0a-34cc-4ae2-93e7-e1eefa89e354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "561c203cf74349ab922809664b2479fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/674 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_samples = 200\n",
    "sampled_label_img = np.zeros((center_coords.shape[1] + 1, *embeddings.shape[1:]), dtype=np.int32)\n",
    "\n",
    "for i in tqdm(range(center_coords.shape[1])):\n",
    "    if covs[i][0, 0] != 0 and covs[i][1,1] != 0:\n",
    "        mvg = torch.distributions.MultivariateNormal(estimated_centers[i], covs[i])\n",
    "        samples = mvg.sample((n_samples,)).T\n",
    "    else:\n",
    "        samples = torch.repeat_interleave(estimated_centers[i].unsqueeze(0), n_samples, dim=0).T\n",
    "    dists = torch.norm(embeddings.unsqueeze(1) - samples.unsqueeze(-1).unsqueeze(-1), dim=0, p=None)\n",
    "    sigma = model.hparams.margin * (-2 * np.log(0.5)) ** -0.5\n",
    "    rois = torch.sum(torch.exp(-0.5 * (dists / sigma) ** 2) >= 0.5, dim=0).type(torch.int32)\n",
    "\n",
    "    sampled_label_img[i+1] = rois.detach().cpu().numpy()\n",
    "\n",
    "uncertainty = sampled_label_img.astype(np.float32) / float(n_samples)\n",
    "uncertainty_counts = np.sum(uncertainty > 0, axis=0)\n",
    "aggregated_uncertainty = np.true_divide(np.sum(uncertainty, axis=0), uncertainty_counts, where=uncertainty_counts>0)\n",
    "# sampled_label_img = np.argmax(sampled_label_img * (uncertainty > certainty_th), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "85acdba8-59be-4cdf-939e-5f780b69180e",
   "metadata": {},
   "outputs": [],
   "source": [
    "certainty_th = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9db17fd8-11d8-40ef-bd11-cc08d738b615",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_labeling = np.argmax(sampled_label_img * (uncertainty > certainty_th), axis=0)# * fg_mask.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "39742a99-8eaf-43df-97a2-006180551b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "cleaned_sampled_label_img = sampled_label_img.copy()\n",
    "cleaned_uncertainty = uncertainty.copy()\n",
    "tmp = np.sum(cleaned_sampled_label_img * (cleaned_uncertainty > 0), axis=0) > n_samples\n",
    "\n",
    "overlapping_labels = cleaned_sampled_label_img * tmp\n",
    "\n",
    "overlapping_labels.max()\n",
    "\n",
    "overlapping_label_ids = np.arange(overlapping_labels.shape[0])[np.max(overlapping_labels > 0, axis=(1,2))]\n",
    "\n",
    "merge_candidates = {}\n",
    "ths = 0\n",
    "for i in range(len(overlapping_label_ids)):\n",
    "    current = overlapping_label_ids[i]\n",
    "    for j in range(i+1,len(overlapping_label_ids)):\n",
    "        target = overlapping_label_ids[j]\n",
    "        intersection = np.sum(np.logical_and(cleaned_sampled_label_img[current] > ths, cleaned_sampled_label_img[target] > ths))\n",
    "        union = np.sum(np.logical_or(cleaned_sampled_label_img[current] > ths, cleaned_sampled_label_img[target] > ths))\n",
    "        iou = intersection / union\n",
    "        if iou > 0.95:\n",
    "            print(iou)\n",
    "            added = False\n",
    "            for k, v in merge_candidates.items():\n",
    "                added += current in v\n",
    "\n",
    "            if not added:\n",
    "                if current not in merge_candidates.keys():\n",
    "                    merge_candidates[current] = []\n",
    "                merge_candidates[current].append(target)\n",
    "\n",
    "\n",
    "print(merge_candidates)\n",
    "\n",
    "for k, v in merge_candidates.items():\n",
    "    for label_id in v:\n",
    "        cleaned_sampled_label_img[k] = np.clip(cleaned_sampled_label_img[k] + cleaned_sampled_label_img[label_id], 0, n_samples)\n",
    "        cleaned_uncertainty[k] = np.clip(cleaned_uncertainty[k] + cleaned_uncertainty[label_id], 0, 1)\n",
    "        cleaned_sampled_label_img[label_id] *= 0\n",
    "        cleaned_uncertainty[label_id] *= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d6884c3c-1217-4e8c-97d4-b1238a8b7a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_labeling = np.argmax(cleaned_sampled_label_img * (cleaned_uncertainty > certainty_th), axis=0)#* fg_mask.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "519efc25-5da5-4698-877c-31271b546281",
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.matching import matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8a2538e2-9103-4550-9439-82c683332e01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Matching(criterion='iou', thresh=0.5, fp=164, tp=509, fn=67, precision=0.7563150074294205, recall=0.8836805555555556, accuracy=0.6878378378378378, f1=0.8150520416333067, n_true=576, n_pred=673, mean_true_score=0.6667058732774522, mean_matched_score=0.7544647996224214, panoptic_quality=0.6149280752727182)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matching(\n",
    "    y.detach().cpu().numpy()[0, 0], \n",
    "    sampled_labeling[padding:-padding, padding:-padding])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "79388daa-1cf2-47bb-b627-c42fffc61911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Matching(criterion='iou', thresh=0.5, fp=164, tp=509, fn=67, precision=0.7563150074294205, recall=0.8836805555555556, accuracy=0.6878378378378378, f1=0.8150520416333067, n_true=576, n_pred=673, mean_true_score=0.6667058732774522, mean_matched_score=0.7544647996224214, panoptic_quality=0.6149280752727182)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matching(\n",
    "    y.detach().cpu().numpy()[0, 0], \n",
    "    cleaned_labeling[padding:-padding, padding:-padding])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2d712dcc-fc57-46fa-a265-9686ce1edd4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Matching(criterion='iou', thresh=0.5, fp=151, tp=505, fn=71, precision=0.7698170731707317, recall=0.8767361111111112, accuracy=0.6946354883081155, f1=0.8198051948051948, n_true=576, n_pred=656, mean_true_score=0.6616769896613227, mean_matched_score=0.7547048436533107, panoptic_quality=0.6187109513716265)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matching(y.detach().cpu().numpy()[0, 0], instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2f6a0842-8e39-4f01-b033-8369b67a403f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Labels layer 'cleand labeling' at 0x7aad8a7a6660>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "viewer.add_labels(cleaned_labeling[padding:-padding, padding:-padding], name='cleand labeling')\n",
    "# viewer.add_image(aggregated_uncertainty[padding:-padding, padding:-padding], name='uncertainty', visible=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "16cd74d7-4e9d-4d1c-be74-2afa1293522b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Labels layer 'sampled' at 0x7aad8a7feb40>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer.add_labels(sampled_labeling[padding:-padding, padding:-padding], name='sampled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ca5f18-6e3d-4300-a667-790ff1bbbb2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
